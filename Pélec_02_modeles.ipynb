{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a447af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479648c4",
   "metadata": {},
   "source": [
    "On récupère les bases de données nettoyées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c08178",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = pd.read_csv('data_2015_cleaned.csv')\n",
    "data_2016 = pd.read_csv('data_2016_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00817ef",
   "metadata": {},
   "source": [
    "# Régressions avec les données déclaratives\n",
    "On  va à présent réaliser des régressions pour prédire les variables suivantes, **sans utiliser le score ENERGYSTAR**:\n",
    "- TotalGHGEmissions\n",
    "- SiteEnergyUse(kBtu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf553d",
   "metadata": {},
   "source": [
    "## Définitions générales\n",
    "On défini les entrées pour nos régressions ainsi que la sortie attendue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2da577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_in: Colonnes en entrée dans les régressions\n",
    "cols_in = ['YearBuilt', 'NumberofFloors', 'PropertyGFABuilding(s)', 'Latitude', 'Longitude']\n",
    "# col_out: Colonne en sortie dans les régressions\n",
    "col_out = 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a516136",
   "metadata": {},
   "source": [
    "Comme on l'a vu durant l'ACP, **la variable avec le nombre de bâtiments n'est pas petinente**. On l'exclu donc de nos entrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19435c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_2015, data_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741a0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_in = data[cols_in]  # Tableau 2d avec les valeurs des variables pour chaque entrée\n",
    "reg_out = data[col_out]  # Liste de vecteurs à 1d avec les valeurs de sortie\n",
    "# Standardisation des entrées\n",
    "# std_scale: Scaler pour nos données d'entrée\n",
    "std_scale = preprocessing.StandardScaler().fit(reg_in)\n",
    "reg_in_scale = std_scale.transform(reg_in)  # Nos entrées standardisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72bb96f",
   "metadata": {},
   "source": [
    "## Régressions pour SiteEnergyUse(kBtu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19076b2",
   "metadata": {},
   "source": [
    "### Baseline - Régression linéaire classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e505f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with_cv(regression, reg_name, scoring='r2', cv=3):\n",
    "    \"\"\"Entraîne un modèle avec validation croisée et affiche les temps d'exécution\"\"\"\n",
    "    # scores: Scores obtenus avec la validation croisée\n",
    "    scores = cross_validate(regression, reg_in_scale, reg_out, scoring='r2', cv=3)\n",
    "    print(\"Score avec %s: R2=%.3f\" % (reg_name, scores['test_score'].mean()))\n",
    "    print(\"Temps entraînement: %.3fs\" % scores['fit_time'].sum())\n",
    "    print(\"Temps scoring: %.3fs\" % scores['score_time'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc483291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression linéaire: R2=0.485\n",
      "Temps entraînement: 0.042s\n",
      "Temps scoring: 0.005s\n"
     ]
    }
   ],
   "source": [
    "# reg_lin: Régression linéaire\n",
    "reg_lin = linear_model.LinearRegression()\n",
    "fit_with_cv(reg_lin, \"régression linéaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe52347",
   "metadata": {},
   "source": [
    "On va maintenant essayer plusieurs autres types de régressions pour améliorer les performances de cette régression de base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f974f",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "On va réaliser une régression Rigde, avec une **recherche en grille** des meilleurs paramètres et une **validation croisée**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65dd2780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression Rigde: R2=0.485\n",
      "Temps entraînement: 0.006s\n",
      "Temps scoring: 0.002s\n"
     ]
    }
   ],
   "source": [
    "# ridge: Régression Ridge\n",
    "rigde = linear_model.Ridge(alpha=25)\n",
    "fit_with_cv(rigde, \"régression Rigde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937867e",
   "metadata": {},
   "source": [
    "Avec cette régression, augmenter le alpha ne fait que diminuer le R2: **Limiter la taille des poids n'a pas d'impact.** Cela signifie qu'il n'y à pas de sur-apprentissage, ni de corrélations entre nos entrées. On s'attend à observer le même phénomène pour la régression Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cadb5",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "On va maintenant appliquer une régression Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a20afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression Lasso: R2=0.485\n",
      "Temps entraînement: 0.004s\n",
      "Temps scoring: 0.001s\n"
     ]
    }
   ],
   "source": [
    "# lasso: Régressions Lasso\n",
    "lasso = linear_model.Lasso(alpha=1000)\n",
    "fit_with_cv(lasso, \"régression Lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5db913",
   "metadata": {},
   "source": [
    "Quelque soit la forme de la norme utilisée, **limiter le poids des features n'a pas d'impact**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e009d0",
   "metadata": {},
   "source": [
    "À plus forte raison, **utiliser l'elastic net n'a pas d'intérêt** ici."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28feed9",
   "metadata": {},
   "source": [
    "### k-nn\n",
    "Essayon d'appliquer la forme régressive de l'algorithme des plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8be582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec k-nn: R2=0.723\n",
      "Temps entraînement: 0.008s\n",
      "Temps scoring: 0.037s\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "fit_with_cv(knn, \"k-nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62eb1ad",
   "metadata": {},
   "source": [
    "Quand on augmente le nombre de voisins pris en compte, on diminue le R2. **Ce n'est donc probablement pas le bon type de modèle**, même si il est déjà bien meilleur que les régressions linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703bb44",
   "metadata": {},
   "source": [
    "### Forêt aléatoire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "604d36b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec forêt aléatoire: R2=0.799\n",
      "Temps entraînement: 0.395s\n",
      "Temps scoring: 0.013s\n"
     ]
    }
   ],
   "source": [
    "# rand_forest: Régression de forêt aléatoire\n",
    "rand_forest = RandomForestRegressor(n_estimators=13, max_depth=14)\n",
    "fit_with_cv(rand_forest, \"forêt aléatoire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaee641",
   "metadata": {},
   "source": [
    "Par rapport au modèle précédent, **on a gagné ~8 points**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a5074",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169f00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec gradient boosting: R2=0.851\n",
      "Temps entraînement: 1.975s\n",
      "Temps scoring: 0.013s\n"
     ]
    }
   ],
   "source": [
    "# grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grad_boost = GradientBoostingRegressor(learning_rate=0.4, n_estimators=50, max_depth=10)\n",
    "fit_with_cv(grad_boost, \"gradient boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483427b3",
   "metadata": {},
   "source": [
    "On optimise ce modèle qui a donné les meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae44705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Gradient boosting optimisé: 0.87\n",
      "Temps entraînement: 94.439s\n",
      "Temps score: 0.646s\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': [0.35+i*0.02 for i in range(6)],\n",
    "          'n_estimators':[48+i for i in range(5)],\n",
    "          'max_depth': [8+i for i in range(5)]}\n",
    "# grid_grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grid_grad_boost = GridSearchCV(GradientBoostingRegressor(), params, cv=3)\n",
    "grid_grad_boost.fit(reg_in_scale, reg_out)\n",
    "cv_results = grid_grad_boost.cv_results_\n",
    "print(\"Score Gradient boosting optimisé: %.2f\" % grid_grad_boost.best_score_)\n",
    "print(\"Temps entraînement: %.3fs\" % (cv_results['mean_fit_time'].sum()+grid_grad_boost.refit_time_))\n",
    "print(\"Temps score: %.3fs\" % cv_results['mean_score_time'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ac2a7",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Notre modèle final utilisant **le gradient bossting atteint un R2 de 0.87**, sachant qu'avec une régression linéaire simple, on atteignait à peine 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688805ca",
   "metadata": {},
   "source": [
    "## Régressions pour TotalGHGEmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b28151c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_out = 'TotalGHGEmissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3684782",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out = data[col_out]  # Liste de vecteurs à 1d avec les valeurs de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d4bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression linéaire: R2=0.282\n",
      "Temps entraînement: 0.009s\n",
      "Temps scoring: 0.003s\n"
     ]
    }
   ],
   "source": [
    "# reg_lin: Régression linéaire\n",
    "reg_lin = linear_model.LinearRegression()\n",
    "fit_with_cv(reg_lin, \"régression linéaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eded0be",
   "metadata": {},
   "source": [
    "On va maintenant essayer plusieurs autres types de régressions pour améliorer les performances de cette régression de base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0182652",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "On va réaliser une régression Rigde, avec une **recherche en grille** des meilleurs paramètres et une **validation croisée**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc5824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression Rigde: R2=0.282\n",
      "Temps entraînement: 0.004s\n",
      "Temps scoring: 0.001s\n"
     ]
    }
   ],
   "source": [
    "# ridge: Régression Ridge\n",
    "rigde = linear_model.Ridge(alpha=25)\n",
    "fit_with_cv(rigde, \"régression Rigde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2334420",
   "metadata": {},
   "source": [
    "Avec cette régression, augmenter le alpha ne fait que diminuer le R2: **Limiter la taille des poids n'a pas d'impact.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25406fbb",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "On va maintenant appliquer une régression Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb1b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec régression Lasso: R2=0.282\n",
      "Temps entraînement: 0.003s\n",
      "Temps scoring: 0.001s\n"
     ]
    }
   ],
   "source": [
    "# lasso: Régressions Lasso\n",
    "lasso = linear_model.Lasso(alpha=1)\n",
    "fit_with_cv(lasso, \"régression Lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39b8b8",
   "metadata": {},
   "source": [
    "Quelque soit la forme de la norme utilisée, **limiter le poids des features n'a pas d'impact**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2701ee",
   "metadata": {},
   "source": [
    "À plus forte raison, **utiliser l'elastic net n'a pas d'intérêt** ici."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d45e8b",
   "metadata": {},
   "source": [
    "### k-nn\n",
    "Essayon d'appliquer la forme régressive de l'algorithme des plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3baab389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec k-nn: R2=0.572\n",
      "Temps entraînement: 0.010s\n",
      "Temps scoring: 0.040s\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "fit_with_cv(knn, \"k-nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bb8a1",
   "metadata": {},
   "source": [
    "Quand on augmente le nombre de voisins pris en compte, on diminue le R2. **Ce n'est donc probablement pas le bon type de modèle**, même si il est déjà bien meilleur que les régressions linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae96849",
   "metadata": {},
   "source": [
    "### Forêt aléatoire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbcf54a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec forêt aléatoire: R2=0.713\n",
      "Temps entraînement: 0.390s\n",
      "Temps scoring: 0.013s\n"
     ]
    }
   ],
   "source": [
    "# rand_forest: Régression de forêt aléatoire\n",
    "rand_forest = RandomForestRegressor(n_estimators=13, max_depth=14)\n",
    "fit_with_cv(rand_forest, \"forêt aléatoire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d18f09",
   "metadata": {},
   "source": [
    "Par rapport au modèle précédent, **on gagne 24 points**, ce qui est considérable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f0117",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc37c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score avec gradient boosting: R2=0.789\n",
      "Temps entraînement: 1.854s\n",
      "Temps scoring: 0.013s\n"
     ]
    }
   ],
   "source": [
    "# grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grad_boost = GradientBoostingRegressor(learning_rate=0.4, n_estimators=50, max_depth=10)\n",
    "fit_with_cv(grad_boost, \"gradient boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699be72",
   "metadata": {},
   "source": [
    "On optimise ce modèle qui a donné les meilleurs résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b4ca232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Gradient boosting optimisé: 0.81\n",
      "Temps entraînement: 93.833s\n",
      "Temps score: 0.629s\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': [0.35+i*0.02 for i in range(6)],\n",
    "          'n_estimators':[48+i for i in range(5)],\n",
    "          'max_depth': [8+i for i in range(5)]}\n",
    "# grid_grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grid_grad_boost = GridSearchCV(GradientBoostingRegressor(), params, cv=3)\n",
    "grid_grad_boost.fit(reg_in_scale, reg_out)\n",
    "cv_results = grid_grad_boost.cv_results_\n",
    "print(\"Score Gradient boosting optimisé: %.2f\" % grid_grad_boost.best_score_)\n",
    "print(\"Temps entraînement: %.3fs\" % (cv_results['mean_fit_time'].sum()+grid_grad_boost.refit_time_))\n",
    "print(\"Temps score: %.3fs\" % cv_results['mean_score_time'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff2ae9",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Notre modèle final utilisant **le gradient bossting atteint un R2 de 0.81**, sachant qu'avec une régression linéaire simple, on atteignait seulement 0.31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abb82e",
   "metadata": {},
   "source": [
    "# Régressions avec l'ENERGYSTARScore\n",
    "En plus des données déclaratives, ajoutons l'ENERGYSTARScore pour évaluer son impact sur le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "738dad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['ENERGYSTARScore'])\n",
    "cols_in.append('ENERGYSTARScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f2352",
   "metadata": {},
   "source": [
    "## Régressions pour SiteEnergyUse(kBtu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbeabf",
   "metadata": {},
   "source": [
    "On re-définit la sortie..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0db3d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_out = 'SiteEnergyUse(kBtu)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0f6ea",
   "metadata": {},
   "source": [
    "... Ainsi que nos données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa08927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_in = data[cols_in]  # Tableau 2d avec les valeurs des variables pour chaque entrée\n",
    "reg_out = data[col_out]  # Liste de vecteurs à 1d avec les valeurs de sortie\n",
    "# std_scale: Scaler pour nos données d'entrée\n",
    "std_scale = preprocessing.StandardScaler().fit(reg_in)\n",
    "reg_in_scale = std_scale.transform(reg_in)  # Nos entrées standardisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ae10e",
   "metadata": {},
   "source": [
    "Voyons l'**impact sur notre modèle final**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3e1cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Gradient boosting optimisé: 0.86\n",
      "Temps entraînement: 80.022s\n",
      "Temps score: 0.562s\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': [0.35+i*0.02 for i in range(6)],\n",
    "          'n_estimators':[48+i for i in range(5)],\n",
    "          'max_depth': [8+i for i in range(5)]}\n",
    "# grid_grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grid_grad_boost = GridSearchCV(GradientBoostingRegressor(), params, cv=3)\n",
    "grid_grad_boost.fit(reg_in_scale, reg_out)\n",
    "cv_results = grid_grad_boost.cv_results_\n",
    "print(\"Score Gradient boosting optimisé: %.2f\" % grid_grad_boost.best_score_)\n",
    "print(\"Temps entraînement: %.3fs\" % (cv_results['mean_fit_time'].sum()+grid_grad_boost.refit_time_))\n",
    "print(\"Temps score: %.3fs\" % cv_results['mean_score_time'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9aab2",
   "metadata": {},
   "source": [
    "On constate que **cet ajout diminue le R2 d'un point**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ae6e8",
   "metadata": {},
   "source": [
    "## Régressions pour TotalGHGEmissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89795c66",
   "metadata": {},
   "source": [
    "On re-définit la sortie..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8426dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_out = 'TotalGHGEmissions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d137808",
   "metadata": {},
   "source": [
    "... Ainsi que nos données d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9847ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_in = data[cols_in]  # Tableau 2d avec les valeurs des variables pour chaque entrée\n",
    "reg_out = data[col_out]  # Liste de vecteurs à 1d avec les valeurs de sortie\n",
    "# Standardisation des entrées\n",
    "# std_scale: Scaler pour nos données d'entrée\n",
    "std_scale = preprocessing.StandardScaler().fit(reg_in)\n",
    "reg_in_scale = std_scale.transform(reg_in)  # Nos entrées standardisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa2252",
   "metadata": {},
   "source": [
    "Voyons l'**impact sur notre modèle final**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ead1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Gradient boosting optimisé: 0.81\n",
      "Temps entraînement: 92.874s\n",
      "Temps score: 0.615s\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': [0.35+i*0.02 for i in range(6)],\n",
    "          'n_estimators':[48+i for i in range(5)],\n",
    "          'max_depth': [8+i for i in range(5)]}\n",
    "# grid_grad_boost: Régression X-Gradient boosting optimisée avec recherche par grille\n",
    "grid_grad_boost = GridSearchCV(GradientBoostingRegressor(), params, cv=3)\n",
    "grid_grad_boost.fit(reg_in_scale, reg_out)\n",
    "cv_results = grid_grad_boost.cv_results_\n",
    "print(\"Score Gradient boosting optimisé: %.2f\" % grid_grad_boost.best_score_)\n",
    "print(\"Temps entraînement: %.3fs\" % (cv_results['mean_fit_time'].sum()+grid_grad_boost.refit_time_))\n",
    "print(\"Temps score: %.3fs\" % cv_results['mean_score_time'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28a3e4",
   "metadata": {},
   "source": [
    "Avec le score energy star, **Le R2 ne change pas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316859be",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "L'ajout de l'Energy Star Score n'a pas d'intérêt pour nos modèles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p4",
   "language": "python",
   "name": "env_p4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
